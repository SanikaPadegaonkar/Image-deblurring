{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8048013,"sourceType":"datasetVersion","datasetId":4745793},{"sourceId":8057315,"sourceType":"datasetVersion","datasetId":4752358}],"dockerImageVersionId":30207,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nimport random\nimport cv2\nimport os\nimport tensorflow as tf\nfrom tqdm import tqdm\n\nimport time\nimport copy\nfrom skimage.filters import gaussian\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:38:54.750235Z","iopub.execute_input":"2024-04-09T22:38:54.750977Z","iopub.status.idle":"2024-04-09T22:39:06.788046Z","shell.execute_reply.started":"2024-04-09T22:38:54.750866Z","shell.execute_reply":"2024-04-09T22:39:06.786658Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Reference: https://www.kaggle.com/code/chandanakuntala/deblur-images-using-autoencoders-82-acc/notebook","metadata":{}},{"cell_type":"code","source":"#output_root = r'../output/kaggle/working/sharp/'\n\ndef read_images_from_folder(root_folder):\n    clean_frames = []\n    labels = []\n    for class_folder in tqdm(os.listdir(root_folder)):\n        class_path = os.path.join(root_folder, class_folder)\n        \n        #output_class_path = os.path.join(output_root, class_folder)\n        #os.makedirs(output_class_path, exist_ok = True)\n        \n        if os.path.isdir(class_path):\n            for image_file in os.listdir(class_path)[:int(0.1*(len(os.listdir(class_path))))]:\n                if image_file.endswith('.jpg') or image_file.endswith('.png'):\n                    image = tf.keras.preprocessing.image.load_img(class_path + '/' + image_file, target_size=(256,448))\n                    \n                    #image_path = os.path.join(output_class_path, image_file)\n                    #image.save(image_path,'png')\n                    \n                    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n                    clean_frames.append(image)\n                    labels.append(class_folder)  # Assuming the folder name is the label\n    clean_frames = np.array(clean_frames)\n    return clean_frames, labels","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:39:06.790400Z","iopub.execute_input":"2024-04-09T22:39:06.791210Z","iopub.status.idle":"2024-04-09T22:39:06.804607Z","shell.execute_reply.started":"2024-04-09T22:39:06.791168Z","shell.execute_reply":"2024-04-09T22:39:06.802915Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Example usage:\nroot_folder = r'../input/sharpimages/train/train_sharp/'\nclean_frames, labels = read_images_from_folder(root_folder)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:39:06.806959Z","iopub.execute_input":"2024-04-09T22:39:06.808653Z","iopub.status.idle":"2024-04-09T22:42:07.196344Z","shell.execute_reply.started":"2024-04-09T22:39:06.808596Z","shell.execute_reply":"2024-04-09T22:42:07.194974Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"100%|██████████| 240/240 [02:57<00:00,  1.35it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def apply_gaussian_filters(images):\n    filtered_images = []\n    for img in images:\n        #filtered_img_1 = gaussian(img, sigma=0.3, truncate=3.0)\n        filtered_img_1 = cv2.GaussianBlur(img,(3,3),0.3)\n        #filtered_img_2 = gaussian(img, sigma=1, truncate=3.0)\n        filtered_img_2 = cv2.GaussianBlur(img,(7,7),1)\n        #filtered_img_3 = gaussian(img, sigma=1.6, truncate=3.0)\n        filtered_img_3 = cv2.GaussianBlur(img,(11,11),1.6)\n        filtered_images.extend([filtered_img_1, filtered_img_2, filtered_img_3])\n    filtered_images = np.array(filtered_images)\n    return filtered_images","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:42:07.199873Z","iopub.execute_input":"2024-04-09T22:42:07.200343Z","iopub.status.idle":"2024-04-09T22:42:07.209196Z","shell.execute_reply.started":"2024-04-09T22:42:07.200303Z","shell.execute_reply":"2024-04-09T22:42:07.207932Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Assuming images is a list containing the original images\nblurry_frames = apply_gaussian_filters(clean_frames)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:42:07.210709Z","iopub.execute_input":"2024-04-09T22:42:07.211524Z","iopub.status.idle":"2024-04-09T22:43:05.223298Z","shell.execute_reply.started":"2024-04-09T22:42:07.211452Z","shell.execute_reply":"2024-04-09T22:43:05.221169Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(clean_frames[0].shape)\nclean_frames_repeated = np.repeat(clean_frames,3,axis=0)\nprint(clean_frames_repeated.shape)\nprint(blurry_frames.shape)\nprint((clean_frames[0]==clean_frames_repeated[0]).all() and (clean_frames[0]==clean_frames_repeated[1]).all() and (clean_frames[0]==clean_frames_repeated[2]).all())","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:43:05.225714Z","iopub.execute_input":"2024-04-09T22:43:05.226226Z","iopub.status.idle":"2024-04-09T22:43:13.941870Z","shell.execute_reply.started":"2024-04-09T22:43:05.226181Z","shell.execute_reply":"2024-04-09T22:43:13.937042Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(256, 448, 3)\n(7200, 256, 448, 3)\n(7200, 256, 448, 3)\nTrue\n","output_type":"stream"}]},{"cell_type":"markdown","source":"******************************************************************************","metadata":{}},{"cell_type":"markdown","source":"******************************************************************************","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Input\nfrom keras.layers import Conv2D, Flatten\nfrom keras.layers import Reshape, Conv2DTranspose\nfrom keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.utils.vis_utils import plot_model\nfrom keras import backend as K\n\nseed = 21\nrandom.seed = seed\nnp.random.seed = seed","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:43:13.982841Z","iopub.execute_input":"2024-04-09T22:43:13.983795Z","iopub.status.idle":"2024-04-09T22:43:13.993514Z","shell.execute_reply.started":"2024-04-09T22:43:13.983742Z","shell.execute_reply":"2024-04-09T22:43:13.992124Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"x = clean_frames_repeated;\ny = blurry_frames;\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T22:43:14.001125Z","iopub.execute_input":"2024-04-09T22:43:14.002290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train[0].shape)\nprint(y_train[0].shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = random.randint(0, len(clean_frames_repeated)-1)\nprint(r)\nfig = plt.figure()\nfig.subplots_adjust(hspace=0.1, wspace=0.2)\nax = fig.add_subplot(1, 2, 1)\nax.imshow(clean_frames_repeated[r])\nax = fig.add_subplot(1, 2, 2)\nax.imshow(blurry_frames[r])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Network Parameters\ninput_shape = (256, 448, 3)\nbatch_size = 32\nkernel_size = 3\n# latent_dim = 256\nlatent_dim = 128\n\n# Encoder/Decoder number of CNN layers and filters per layer\n#layer_filters = [64, 128, 256]\n#layer_filters = [32,64]\nlayer_filters = [8, 16, 32]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inputs = Input(shape = input_shape, name = 'encoder_input')\nx = inputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for filters in layer_filters:\n    x = Conv2D(filters=filters,\n               kernel_size=kernel_size,\n               strides=2,\n               activation='relu',\n               padding='same')(x)\nshape = K.int_shape(x)\nx = Flatten()(x)\nlatent = Dense(latent_dim, name='latent_vector')(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = Model(inputs, latent, name='encoder')\nencoder.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\nx = Dense(shape[1]*shape[2]*shape[3])(latent_inputs)\nx = Reshape((shape[1], shape[2], shape[3]))(x)\nfor filters in layer_filters[::-1]:\n    x = Conv2DTranspose(filters=filters,\n                        kernel_size=kernel_size,\n                        strides=2,\n                        activation='relu',\n                        padding='same')(x)\n\noutputs = Conv2DTranspose(filters=3,\n                          kernel_size=kernel_size,\n                          activation='sigmoid',\n                          padding='same',\n                          name='decoder_output')(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder = Model(latent_inputs, outputs, name='decoder')\ndecoder.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder = Model(inputs, decoder(encoder(inputs)), name='autoencoder')\nautoencoder.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.compile(loss='mse', optimizer='adam',metrics=[\"acc\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n                               cooldown=0,\n                               patience=5,\n                               verbose=1,\n                               min_lr=0.5e-6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [lr_reducer]\nhistory = autoencoder.fit(blurry_frames,\n                      clean_frames_repeated,\n                      validation_data=(blurry_frames, clean_frames_repeated),\n                      epochs=25,\n                      batch_size=batch_size,\n                      callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n       Input                        Ground Truth                  Predicted Value\")\nfor i in range(3):\n    \n    r = random.randint(0, len(clean_frames_repeated)-1)\n\n    x, y = blurry_frames[r],clean_frames_repeated[r]\n    x_inp=x.reshape(1,128,128,3)\n    result = autoencoder.predict(x_inp)\n    result = result.reshape(128,128,3)\n\n    fig = plt.figure(figsize=(12,10))\n    fig.subplots_adjust(hspace=0.1, wspace=0.2)\n\n    ax = fig.add_subplot(1, 3, 1)\n    ax.imshow(x)\n\n    ax = fig.add_subplot(1, 3, 2)\n    ax.imshow(y)\n\n    ax = fig.add_subplot(1, 3, 3)\n    plt.imshow(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['Train', 'Test'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.xticks(np.arange(0, 101, 25))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.legend(['Train', 'Test'])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.xticks(np.arange(0, 101, 25))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_predict(test_folder):\n    # predicted_images\n    dest_folder = r'./preds/'\n    os.makedirs(dest_folder,exist_ok=True)\n    for image_file in tqdm(os.listdir(test_folder)):\n            if image_file.endswith('.jpg') or image_file.endswith('.png'):\n                image = tf.keras.preprocessing.image.load_img(test_folder + '/' + image_file, target_size=(128,128))\n                image = tf.keras.preprocessing.image.img_to_array(image).astype('float32') / 255\n                #print(image.shape)\n                x_inp=image.reshape(1,128,128,3)\n                pred = autoencoder.predict(x_inp)\n                result = pred.reshape(128,128,3)\n                img = Image.fromarray((result*255).astype(np.uint8))\n                #img_name = \"img_{}_{}.png\".format(i,j)\n                img.save(dest_folder + '/' + image_file)\n    #clean_frames = np.array(clean_frames)\n    #return clean_frames, labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example usage:\ntest_folder = r'../input/customtest/custom_test/blur/'\ncustom_predict(test_folder)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working/preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'file.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}